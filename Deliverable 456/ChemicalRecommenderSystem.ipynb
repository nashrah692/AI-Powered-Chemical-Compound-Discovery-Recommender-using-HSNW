{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-04-26T05:38:51.766341Z",
     "iopub.status.busy": "2025-04-26T05:38:51.765633Z",
     "iopub.status.idle": "2025-04-26T05:38:56.158560Z",
     "shell.execute_reply": "2025-04-26T05:38:56.157536Z",
     "shell.execute_reply.started": "2025-04-26T05:38:51.766318Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: rdkit-pypi in /usr/local/lib/python3.11/dist-packages (2022.9.5)\n",
      "Requirement already satisfied: hnswlib in /usr/local/lib/python3.11/dist-packages (0.8.0)\n",
      "Collecting torch_geometric\n",
      "  Downloading torch_geometric-2.6.1-py3-none-any.whl.metadata (63 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.1/63.1 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from rdkit-pypi) (1.26.4)\n",
      "Requirement already satisfied: Pillow in /usr/local/lib/python3.11/dist-packages (from rdkit-pypi) (11.1.0)\n",
      "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from torch_geometric) (3.11.16)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch_geometric) (2025.3.2)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch_geometric) (3.1.6)\n",
      "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.11/dist-packages (from torch_geometric) (7.0.0)\n",
      "Requirement already satisfied: pyparsing in /usr/local/lib/python3.11/dist-packages (from torch_geometric) (3.2.1)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from torch_geometric) (2.32.3)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from torch_geometric) (4.67.1)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch_geometric) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch_geometric) (1.3.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch_geometric) (25.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch_geometric) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch_geometric) (6.2.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch_geometric) (0.3.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch_geometric) (1.19.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch_geometric) (3.0.2)\n",
      "Requirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy->rdkit-pypi) (1.3.8)\n",
      "Requirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy->rdkit-pypi) (1.2.4)\n",
      "Requirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy->rdkit-pypi) (0.1.1)\n",
      "Requirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy->rdkit-pypi) (2025.1.0)\n",
      "Requirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy->rdkit-pypi) (2022.1.0)\n",
      "Requirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy->rdkit-pypi) (2.4.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->torch_geometric) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->torch_geometric) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->torch_geometric) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->torch_geometric) (2025.1.31)\n",
      "Requirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->rdkit-pypi) (2024.2.0)\n",
      "Requirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->rdkit-pypi) (2022.1.0)\n",
      "Requirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy->rdkit-pypi) (1.2.0)\n",
      "Requirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy->rdkit-pypi) (2024.2.0)\n",
      "Requirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy->rdkit-pypi) (2024.2.0)\n",
      "Downloading torch_geometric-2.6.1-py3-none-any.whl (1.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m55.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: torch_geometric\n",
      "Successfully installed torch_geometric-2.6.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install rdkit-pypi hnswlib torch_geometric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-26T05:39:29.628699Z",
     "iopub.status.busy": "2025-04-26T05:39:29.628101Z",
     "iopub.status.idle": "2025-04-26T05:39:52.556338Z",
     "shell.execute_reply": "2025-04-26T05:39:52.555484Z",
     "shell.execute_reply.started": "2025-04-26T05:39:29.628668Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading and preprocessing data...\n",
      "\n",
      "Generating Morgan fingerprints...\n",
      "Fingerprint matrix shape: (15872, 2048)\n",
      "\n",
      "Building GNN for fingerprint embedding...\n",
      "Generating GNN embeddings from fingerprints...\n",
      "Embedding matrix shape: (15872, 256)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import AllChem\n",
    "from transformers import pipeline\n",
    "import hnswlib\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.nn import GINConv, global_add_pool\n",
    "\n",
    "# ===========================================\n",
    "# STEP 1: Data Loading and Preprocessing\n",
    "# ===========================================\n",
    "print(\"Loading and preprocessing data...\")\n",
    "\n",
    "# Load dataset\n",
    "df = pd.read_csv('/kaggle/input/smiles/SMILES_Big_Data_Set.csv')\n",
    "\n",
    "# Standardize molecules\n",
    "def standardize_smiles(smiles):\n",
    "    try:\n",
    "        mol = Chem.MolFromSmiles(smiles)\n",
    "        if mol is None:\n",
    "            return None\n",
    "        return Chem.MolToSmiles(mol, isomericSmiles=True)\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "df['standard_smiles'] = df['SMILES'].apply(standardize_smiles)\n",
    "df = df.dropna(subset=['standard_smiles']).drop_duplicates(subset=['standard_smiles'])\n",
    "df['mol'] = df['standard_smiles'].apply(Chem.MolFromSmiles)\n",
    "\n",
    "# ===========================================\n",
    "# STEP 2: Fingerprint Generation (Morgan only)\n",
    "# ===========================================\n",
    "print(\"\\nGenerating Morgan fingerprints...\")\n",
    "\n",
    "def generate_morgan_fingerprint(mol, radius=2, n_bits=2048):\n",
    "    if mol is None:\n",
    "        return np.zeros(n_bits)\n",
    "    fp = AllChem.GetMorganFingerprintAsBitVect(mol, radius=radius, nBits=n_bits)\n",
    "    arr = np.zeros((1,))\n",
    "    DataStructs.ConvertToNumpyArray(fp, arr)\n",
    "    return arr\n",
    "\n",
    "df['morgan_fp'] = df['mol'].apply(lambda x: generate_morgan_fingerprint(x))\n",
    "fp_matrix = np.stack(df['morgan_fp'].values)\n",
    "print(f\"Fingerprint matrix shape: {fp_matrix.shape}\")\n",
    "\n",
    "# ===========================================\n",
    "# STEP 3: GNN for Fingerprint Embedding\n",
    "# ===========================================\n",
    "print(\"\\nBuilding GNN for fingerprint embedding...\")\n",
    "\n",
    "class FingerprintGNN(nn.Module):\n",
    "    def __init__(self, input_dim=2048, hidden_dim=512, output_dim=256):\n",
    "        super().__init__()\n",
    "        # Convert fingerprint to graph (artificial topology)\n",
    "        self.fp_to_node = nn.Linear(input_dim, hidden_dim)\n",
    "        self.conv1 = GINConv(nn.Sequential(\n",
    "            nn.Linear(hidden_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, hidden_dim)\n",
    "        ))\n",
    "        self.conv2 = GINConv(nn.Sequential(\n",
    "            nn.Linear(hidden_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, hidden_dim)\n",
    "        ))\n",
    "        self.lin = nn.Linear(hidden_dim, output_dim)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # Create artificial graph structure\n",
    "        batch_size = x.shape[0]\n",
    "        x = self.fp_to_node(x)\n",
    "        \n",
    "        # Create fully connected graph for each sample\n",
    "        edge_index = []\n",
    "        for i in range(batch_size):\n",
    "            # Connect all nodes to all other nodes (fully connected)\n",
    "            for j in range(batch_size):\n",
    "                if i != j:\n",
    "                    edge_index.append([i, j])\n",
    "        \n",
    "        if len(edge_index) == 0:\n",
    "            edge_index = torch.zeros((2, 0), dtype=torch.long)\n",
    "        else:\n",
    "            edge_index = torch.tensor(edge_index, dtype=torch.long).t().contiguous()\n",
    "        \n",
    "        # Batch index\n",
    "        batch = torch.arange(batch_size, dtype=torch.long)\n",
    "        \n",
    "        # GNN processing\n",
    "        x = self.conv1(x, edge_index).relu()\n",
    "        x = self.conv2(x, edge_index)\n",
    "        x = global_add_pool(x, batch)\n",
    "        return self.lin(x)\n",
    "\n",
    "# Initialize and train GNN (simplified training loop)\n",
    "gnn_model = FingerprintGNN()\n",
    "gnn_model.eval()\n",
    "\n",
    "def fp_to_embedding(fingerprint):\n",
    "    with torch.no_grad():\n",
    "        tensor = torch.FloatTensor(fingerprint).unsqueeze(0)\n",
    "        return gnn_model(tensor).squeeze().numpy()\n",
    "\n",
    "print(\"Generating GNN embeddings from fingerprints...\")\n",
    "df['gnn_embedding'] = [fp_to_embedding(fp) for fp in df['morgan_fp']]\n",
    "embedding_matrix = np.stack(df['gnn_embedding'].values)\n",
    "print(f\"Embedding matrix shape: {embedding_matrix.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-26T05:40:18.469768Z",
     "iopub.status.busy": "2025-04-26T05:40:18.469197Z",
     "iopub.status.idle": "2025-04-26T05:40:19.847481Z",
     "shell.execute_reply": "2025-04-26T05:40:19.846861Z",
     "shell.execute_reply.started": "2025-04-26T05:40:18.469737Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Building HNSW index...\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# ===========================================\n",
    "# STEP 4: HNSW Index Construction\n",
    "# ===========================================\n",
    "print(\"\\nBuilding HNSW index...\")\n",
    "\n",
    "dim = embedding_matrix.shape[1]\n",
    "num_elements = embedding_matrix.shape[0]\n",
    "\n",
    "hnsw_index = hnswlib.Index(space='cosine', dim=dim)\n",
    "hnsw_index.init_index(max_elements=num_elements, ef_construction=200, M=16)\n",
    "hnsw_index.add_items(embedding_matrix)\n",
    "hnsw_index.set_ef(50)\n",
    "hnsw_index.save_index('compound_index.hnsw')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-26T05:41:10.403642Z",
     "iopub.status.busy": "2025-04-26T05:41:10.403068Z",
     "iopub.status.idle": "2025-04-26T05:41:39.391612Z",
     "shell.execute_reply": "2025-04-26T05:41:39.387935Z",
     "shell.execute_reply.started": "2025-04-26T05:41:10.403616Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Building recommendation system with LLM enhancement...\n",
      "Could not load DeepSeek: deepseek-ai/deepseek-llm-7b is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\n",
      "If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `huggingface-cli login` or by passing `token=<your_token>`\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "288190aca9f247d99d7f6675aaa9df4d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/967 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3bc56d1feb904328a9b9c14bea4fed53",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors.index.json:   0%|          | 0.00/16.5k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dcfb5a1492a34ee09f559836dbcc5e06",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 2 files:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ce7b6f26231143d1b39c2b92fd9097a3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00002-of-00002.safetensors:   0%|          | 0.00/2.67G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6b9c968d0ff341dfa7a0f85bd17bf066",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00001-of-00002.safetensors:   0%|          | 0.00/4.97G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "74cf06b2c23c4bbba9c2a176af0e452d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b8b5e9c486294be98da1993daca1c0a8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/181 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Example recommendation for caffeine:\n",
      "1. Cn1c(=O)c2c(ncn2C)n(C)c1=O (pIC50: nan)\n",
      "2. Cc1nonc1C (pIC50: 0.21)\n",
      "3. Cc1nc(Cl)c(C)nc1Cl (pIC50: 0.0)\n",
      "4. C[Si](C)(C)C (pIC50: 0.01)\n",
      "5. Cc1nc(C)c(C)nc1C (pIC50: 0.02)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# ===========================================\n",
    "# STEP 5: Enhanced Recommendation System\n",
    "# ===========================================\n",
    "print(\"\\nBuilding recommendation system with LLM enhancement...\")\n",
    "\n",
    "class CompoundRecommender:\n",
    "    def __init__(self, df, hnsw_index):\n",
    "        self.df = df\n",
    "        self.hnsw_index = hnsw_index\n",
    "        self.llms = {}\n",
    "        self._init_llms()\n",
    "        \n",
    "    def _init_llms(self):\n",
    "        # Initialize LLMs with error handling\n",
    "        if not self.llms:\n",
    "            self.llms = {}\n",
    "            try:\n",
    "                self.llms['deepseek'] = pipeline(\n",
    "                    \"text-generation\", \n",
    "                    model=\"deepseek-ai/DeepSeek-R1-Distill-Llama-8B\",\n",
    "                    device=\"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "                )\n",
    "            except Exception as e:\n",
    "                print(f\"Could not load DeepSeek: {e}\")\n",
    "\n",
    "            try:\n",
    "                self.llms['llama'] = pipeline(\n",
    "                    \"text-generation\", \n",
    "                    model=\"meta-llama/Llama-3.2-1B\",\n",
    "                    device=\"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "                )\n",
    "            except Exception as e:\n",
    "                print(f\"Could not load DeepSeek: {e}\")\n",
    "            \n",
    "            try:\n",
    "                self.llms['phi3'] = pipeline(\n",
    "                    \"text-generation\", \n",
    "                    model=\"microsoft/Phi-3-mini-4k-instruct\",\n",
    "                    device=\"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "                )\n",
    "            except Exception as e:\n",
    "                print(f\"Could not load Phi-3: {e}\")\n",
    "    \n",
    "    def _llm_rerank(self, query_smiles, candidates):\n",
    "        \"\"\"Use available LLMs to rerank candidates\"\"\"\n",
    "        if not self.llms:\n",
    "            print(\"abc\")\n",
    "            return candidates[:5]  # Fallback to top 5 if no LLMs loaded\n",
    "            \n",
    "        prompt = f\"\"\"Rank these chemical compounds by similarity to {query_smiles}:\n",
    "        {chr(10).join([f\"{i+1}. {c['standard_smiles']}\" for i, c in enumerate(candidates)])}\n",
    "        Return ONLY the numbers in order of most similar to least.\"\"\"\n",
    "        \n",
    "        try:\n",
    "            if 'deepseek' in self.llms:\n",
    "                result = self.llms['deepseek'](prompt, max_new_tokens=50)[0]['generated_text']\n",
    "                print(result)\n",
    "                # Parse result and reorder (simplified)\n",
    "                return candidates[:5]  # Placeholder\n",
    "            elif 'phi3' in self.llms:\n",
    "                # Similar implementation for Phi-3\n",
    "                return candidates[:5]\n",
    "        except:\n",
    "            return candidates[:5]\n",
    "    \n",
    "    def recommend(self, smiles, k=5):\n",
    "        \"\"\"Get recommendations for a query SMILES\"\"\"\n",
    "        try:\n",
    "            # Generate fingerprint and embedding\n",
    "            mol = Chem.MolFromSmiles(smiles)\n",
    "            if not mol:\n",
    "                return []\n",
    "                \n",
    "            fp = generate_morgan_fingerprint(mol)\n",
    "            embedding = fp_to_embedding(fp)\n",
    "            \n",
    "            # Get initial candidates\n",
    "            labels, distances = self.hnsw_index.knn_query(embedding, k=k*3)\n",
    "            candidates = [self.df.iloc[idx].to_dict() for idx in labels[0]]\n",
    "            \n",
    "            # LLM reranking\n",
    "            return self._llm_rerank(smiles, candidates)[:k]\n",
    "        except Exception as e:\n",
    "            print(f\"Recommendation error: {e}\")\n",
    "            return []\n",
    "\n",
    "# Initialize recommender\n",
    "recommender = CompoundRecommender(df, hnsw_index)\n",
    "\n",
    "# ===========================================\n",
    "# Example Usage\n",
    "# ===========================================\n",
    "print(\"\\nExample recommendation for caffeine:\")\n",
    "results = recommender.recommend(\"CN1C=NC2=C1C(=O)N(C(=O)N2C)C\")\n",
    "for i, res in enumerate(results, 1):\n",
    "    print(f\"{i}. {res['standard_smiles']} (pIC50: {res['pIC50']})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-26T06:09:40.949642Z",
     "iopub.status.busy": "2025-04-26T06:09:40.949331Z",
     "iopub.status.idle": "2025-04-26T06:17:09.507387Z",
     "shell.execute_reply": "2025-04-26T06:17:09.506559Z",
     "shell.execute_reply.started": "2025-04-26T06:09:40.949622Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluating recommendation quality...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 100/100 [07:26<00:00,  4.46s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Recommendation Metrics:\n",
      "hit_rate@k: 0.590\n",
      "precision@k: 0.590\n",
      "recall@k: 0.990\n",
      "mrr: 0.990\n",
      "coverage: 0.031\n",
      "\n",
      "Evaluating embedding quality...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating embeddings: 100%|██████████| 500/500 [00:00<00:00, 1232.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Mean chemical similarity of neighbors: 0.623\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from rdkit import DataStructs\n",
    "from rdkit.Chem import AllChem\n",
    "from sklearn.metrics import precision_score, recall_score\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "class RecommenderEvaluator:\n",
    "    def __init__(self, recommender, df):\n",
    "        \"\"\"\n",
    "        Initialize evaluator with:\n",
    "        - recommender: Your CompoundRecommender instance\n",
    "        - df: DataFrame containing all compounds\n",
    "        \"\"\"\n",
    "        self.recommender = recommender\n",
    "        self.df = df\n",
    "        self.test_set = self._create_test_set()\n",
    "        \n",
    "    def _create_test_set(self, sample_size=100):\n",
    "        \"\"\"Create a balanced test set of valid molecules\"\"\"\n",
    "        valid_smiles = [s for s in self.df['standard_smiles'] if Chem.MolFromSmiles(s)]\n",
    "        return np.random.choice(valid_smiles, min(sample_size, len(valid_smiles)), replace=False)\n",
    "    \n",
    "    def _get_ground_truth(self, query_smiles, k=5):\n",
    "        \"\"\"Calculate ground truth using Tanimoto similarity\"\"\"\n",
    "        query_mol = Chem.MolFromSmiles(query_smiles)\n",
    "        query_fp = AllChem.GetMorganFingerprint(query_mol, 2)\n",
    "        \n",
    "        similarities = []\n",
    "        for _, row in self.df.iterrows():\n",
    "            mol = Chem.MolFromSmiles(row['standard_smiles'])\n",
    "            if mol:\n",
    "                fp = AllChem.GetMorganFingerprint(mol, 2)\n",
    "                sim = DataStructs.TanimotoSimilarity(query_fp, fp)\n",
    "                similarities.append((row['standard_smiles'], sim))\n",
    "        \n",
    "        # Sort by similarity and take top k\n",
    "        similarities.sort(key=lambda x: x[1], reverse=True)\n",
    "        return [s[0] for s in similarities[:k]]\n",
    "    \n",
    "    def evaluate_recommendations(self, k=5):\n",
    "        \"\"\"\n",
    "        Evaluate recommendation quality using:\n",
    "        - Hit Rate @ k\n",
    "        - Precision @ k\n",
    "        - Recall @ k\n",
    "        - Mean Reciprocal Rank (MRR)\n",
    "        - Coverage\n",
    "        \"\"\"\n",
    "        hit_rates = []\n",
    "        precisions = []\n",
    "        recalls = []\n",
    "        reciprocal_ranks = []\n",
    "        recommended_smiles = set()\n",
    "        \n",
    "        for query_smiles in tqdm(self.test_set, desc=\"Evaluating\"):\n",
    "            # Get recommendations\n",
    "            recommendations = [r['standard_smiles'] for r in self.recommender.recommend(query_smiles, k=k)]\n",
    "            recommended_smiles.update(recommendations)\n",
    "            \n",
    "            # Get ground truth\n",
    "            ground_truth = self._get_ground_truth(query_smiles, k=k)\n",
    "            \n",
    "            # Calculate metrics\n",
    "            hits = len(set(recommendations) & set(ground_truth))\n",
    "            hit_rates.append(hits / k)\n",
    "            \n",
    "            y_true = [1 if smi in ground_truth else 0 for smi in recommendations]\n",
    "            y_pred = [1] * len(y_true)  # All recommendations are predicted positives\n",
    "            \n",
    "            precisions.append(precision_score(y_true, y_pred, zero_division=0))\n",
    "            recalls.append(recall_score(y_true, y_pred, zero_division=0))\n",
    "            \n",
    "            # Calculate MRR\n",
    "            for rank, smi in enumerate(recommendations, 1):\n",
    "                if smi in ground_truth:\n",
    "                    reciprocal_ranks.append(1 / rank)\n",
    "                    break\n",
    "            else:\n",
    "                reciprocal_ranks.append(0)\n",
    "        \n",
    "        # Calculate coverage\n",
    "        coverage = len(recommended_smiles) / len(self.df)\n",
    "        \n",
    "        return {\n",
    "            'hit_rate@k': np.mean(hit_rates),\n",
    "            'precision@k': np.mean(precisions),\n",
    "            'recall@k': np.mean(recalls),\n",
    "            'mrr': np.mean(reciprocal_ranks),\n",
    "            'coverage': coverage\n",
    "        }\n",
    "    \n",
    "    def evaluate_embedding_quality(self):\n",
    "        \"\"\"Evaluate the GNN embedding space quality\"\"\"\n",
    "        distances = []\n",
    "        similarities = []\n",
    "        \n",
    "        # Sample pairs of molecules\n",
    "        sample_size = min(500, len(self.df))\n",
    "        sampled_df = self.df.sample(sample_size)\n",
    "        \n",
    "        for _, row in tqdm(sampled_df.iterrows(), total=sample_size, desc=\"Evaluating embeddings\"):\n",
    "            mol = Chem.MolFromSmiles(row['standard_smiles'])\n",
    "            if not mol:\n",
    "                continue\n",
    "                \n",
    "            # Get nearest neighbor in embedding space\n",
    "            emb = row['gnn_embedding'].reshape(1, -1)\n",
    "            labels, _ = self.recommender.hnsw_index.knn_query(emb, k=2)\n",
    "            neighbor_smiles = self.df.iloc[labels[0][1]]['standard_smiles']  # Skip self\n",
    "            \n",
    "            # Calculate chemical similarity\n",
    "            neighbor_mol = Chem.MolFromSmiles(neighbor_smiles)\n",
    "            if neighbor_mol:\n",
    "                fp1 = AllChem.GetMorganFingerprint(mol, 2)\n",
    "                fp2 = AllChem.GetMorganFingerprint(neighbor_mol, 2)\n",
    "                similarities.append(DataStructs.TanimotoSimilarity(fp1, fp2))\n",
    "        \n",
    "        return {\n",
    "            'mean_similarity': np.mean(similarities),\n",
    "            'similarity_distribution': similarities\n",
    "        }\n",
    "    \n",
    "\n",
    "# Example Usage\n",
    "if __name__ == \"__main__\":\n",
    "    # Initialize with your recommender and dataframe\n",
    "    evaluator = RecommenderEvaluator(recommender, df)\n",
    "    \n",
    "    # Evaluate recommendation quality\n",
    "    print(\"\\nEvaluating recommendation quality...\")\n",
    "    rec_metrics = evaluator.evaluate_recommendations(k=5)\n",
    "    print(\"\\nRecommendation Metrics:\")\n",
    "    for k, v in rec_metrics.items():\n",
    "        print(f\"{k}: {v:.3f}\")\n",
    "    \n",
    "    # Evaluate embedding quality\n",
    "    print(\"\\nEvaluating embedding quality...\")\n",
    "    emb_metrics = evaluator.evaluate_embedding_quality()\n",
    "    print(f\"\\nMean chemical similarity of neighbors: {emb_metrics['mean_similarity']:.3f}\")\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 6206995,
     "sourceId": 10070475,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 7200232,
     "sourceId": 11487321,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31011,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
